{"format": "torch", "nodes": [{"name": "conv1", "id": 139931209620016, "class_name": "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)", "parameters": [["weight", [64, 3, 7, 7]]], "output_shape": [[4, 64, 128, 128]], "num_parameters": [9408]}, {"name": "bn1", "id": 139931209620448, "class_name": "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)", "parameters": [["weight", [64]], ["bias", [64]]], "output_shape": [[4, 64, 128, 128]], "num_parameters": [64, 64]}, {"name": "act1", "id": 139931209620160, "class_name": "ReLU(inplace=True)", "parameters": [], "output_shape": [[4, 64, 128, 128]], "num_parameters": []}, {"name": "maxpool", "id": 139931209620208, "class_name": "MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)", "parameters": [], "output_shape": [[4, 64, 64, 64]], "num_parameters": []}, {"name": "layer1.0", "id": 139931209619632, "class_name": "Bottleneck(\n  (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act1): ReLU(inplace=True)\n  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act2): ReLU(inplace=True)\n  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act3): ReLU(inplace=True)\n  (downsample): Sequential(\n    (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n)", "parameters": [["conv1.weight", [64, 64, 1, 1]], ["bn1.weight", [64]], ["bn1.bias", [64]], ["conv2.weight", [64, 64, 3, 3]], ["bn2.weight", [64]], ["bn2.bias", [64]], ["conv3.weight", [256, 64, 1, 1]], ["bn3.weight", [256]], ["bn3.bias", [256]], ["downsample.0.weight", [256, 64, 1, 1]], ["downsample.1.weight", [256]], ["downsample.1.bias", [256]]], "output_shape": [[4, 256, 64, 64]], "num_parameters": [4096, 64, 64, 36864, 64, 64, 16384, 256, 256, 16384, 256, 256]}, {"name": "layer1.1", "id": 139931209619104, "class_name": "Bottleneck(\n  (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act1): ReLU(inplace=True)\n  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act2): ReLU(inplace=True)\n  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act3): ReLU(inplace=True)\n)", "parameters": [["conv1.weight", [64, 256, 1, 1]], ["bn1.weight", [64]], ["bn1.bias", [64]], ["conv2.weight", [64, 64, 3, 3]], ["bn2.weight", [64]], ["bn2.bias", [64]], ["conv3.weight", [256, 64, 1, 1]], ["bn3.weight", [256]], ["bn3.bias", [256]]], "output_shape": [[4, 256, 64, 64]], "num_parameters": [16384, 64, 64, 36864, 64, 64, 16384, 256, 256]}, {"name": "layer1.2", "id": 139931209618240, "class_name": "Bottleneck(\n  (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act1): ReLU(inplace=True)\n  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act2): ReLU(inplace=True)\n  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act3): ReLU(inplace=True)\n)", "parameters": [["conv1.weight", [64, 256, 1, 1]], ["bn1.weight", [64]], ["bn1.bias", [64]], ["conv2.weight", [64, 64, 3, 3]], ["bn2.weight", [64]], ["bn2.bias", [64]], ["conv3.weight", [256, 64, 1, 1]], ["bn3.weight", [256]], ["bn3.bias", [256]]], "output_shape": [[4, 256, 64, 64]], "num_parameters": [16384, 64, 64, 36864, 64, 64, 16384, 256, 256]}, {"name": "layer2.0", "id": 139931209617520, "class_name": "Bottleneck(\n  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act1): ReLU(inplace=True)\n  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act2): ReLU(inplace=True)\n  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act3): ReLU(inplace=True)\n  (downsample): Sequential(\n    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n)", "parameters": [["conv1.weight", [128, 256, 1, 1]], ["bn1.weight", [128]], ["bn1.bias", [128]], ["conv2.weight", [128, 128, 3, 3]], ["bn2.weight", [128]], ["bn2.bias", [128]], ["conv3.weight", [512, 128, 1, 1]], ["bn3.weight", [512]], ["bn3.bias", [512]], ["downsample.0.weight", [512, 256, 1, 1]], ["downsample.1.weight", [512]], ["downsample.1.bias", [512]]], "output_shape": [[4, 512, 32, 32]], "num_parameters": [32768, 128, 128, 147456, 128, 128, 65536, 512, 512, 131072, 512, 512]}, {"name": "layer2.1", "id": 139931210378496, "class_name": "Bottleneck(\n  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act1): ReLU(inplace=True)\n  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act2): ReLU(inplace=True)\n  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act3): ReLU(inplace=True)\n)", "parameters": [["conv1.weight", [128, 512, 1, 1]], ["bn1.weight", [128]], ["bn1.bias", [128]], ["conv2.weight", [128, 128, 3, 3]], ["bn2.weight", [128]], ["bn2.bias", [128]], ["conv3.weight", [512, 128, 1, 1]], ["bn3.weight", [512]], ["bn3.bias", [512]]], "output_shape": [[4, 512, 32, 32]], "num_parameters": [65536, 128, 128, 147456, 128, 128, 65536, 512, 512]}, {"name": "layer2.2", "id": 139931210377968, "class_name": "Bottleneck(\n  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act1): ReLU(inplace=True)\n  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act2): ReLU(inplace=True)\n  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act3): ReLU(inplace=True)\n)", "parameters": [["conv1.weight", [128, 512, 1, 1]], ["bn1.weight", [128]], ["bn1.bias", [128]], ["conv2.weight", [128, 128, 3, 3]], ["bn2.weight", [128]], ["bn2.bias", [128]], ["conv3.weight", [512, 128, 1, 1]], ["bn3.weight", [512]], ["bn3.bias", [512]]], "output_shape": [[4, 512, 32, 32]], "num_parameters": [65536, 128, 128, 147456, 128, 128, 65536, 512, 512]}, {"name": "layer2.3", "id": 139931210377440, "class_name": "Bottleneck(\n  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act1): ReLU(inplace=True)\n  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act2): ReLU(inplace=True)\n  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act3): ReLU(inplace=True)\n)", "parameters": [["conv1.weight", [128, 512, 1, 1]], ["bn1.weight", [128]], ["bn1.bias", [128]], ["conv2.weight", [128, 128, 3, 3]], ["bn2.weight", [128]], ["bn2.bias", [128]], ["conv3.weight", [512, 128, 1, 1]], ["bn3.weight", [512]], ["bn3.bias", [512]]], "output_shape": [[4, 512, 32, 32]], "num_parameters": [65536, 128, 128, 147456, 128, 128, 65536, 512, 512]}, {"name": "layer3.0", "id": 139931210376384, "class_name": "Bottleneck(\n  (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act1): ReLU(inplace=True)\n  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act2): ReLU(inplace=True)\n  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act3): ReLU(inplace=True)\n  (downsample): Sequential(\n    (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n)", "parameters": [["conv1.weight", [256, 512, 1, 1]], ["bn1.weight", [256]], ["bn1.bias", [256]], ["conv2.weight", [256, 256, 3, 3]], ["bn2.weight", [256]], ["bn2.bias", [256]], ["conv3.weight", [1024, 256, 1, 1]], ["bn3.weight", [1024]], ["bn3.bias", [1024]], ["downsample.0.weight", [1024, 512, 1, 1]], ["downsample.1.weight", [1024]], ["downsample.1.bias", [1024]]], "output_shape": [[4, 1024, 16, 16]], "num_parameters": [131072, 256, 256, 589824, 256, 256, 262144, 1024, 1024, 524288, 1024, 1024]}, {"name": "layer3.1", "id": 139931210375328, "class_name": "Bottleneck(\n  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act1): ReLU(inplace=True)\n  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act2): ReLU(inplace=True)\n  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act3): ReLU(inplace=True)\n)", "parameters": [["conv1.weight", [256, 1024, 1, 1]], ["bn1.weight", [256]], ["bn1.bias", [256]], ["conv2.weight", [256, 256, 3, 3]], ["bn2.weight", [256]], ["bn2.bias", [256]], ["conv3.weight", [1024, 256, 1, 1]], ["bn3.weight", [1024]], ["bn3.bias", [1024]]], "output_shape": [[4, 1024, 16, 16]], "num_parameters": [262144, 256, 256, 589824, 256, 256, 262144, 1024, 1024]}, {"name": "layer3.2", "id": 139931210348384, "class_name": "Bottleneck(\n  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act1): ReLU(inplace=True)\n  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act2): ReLU(inplace=True)\n  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act3): ReLU(inplace=True)\n)", "parameters": [["conv1.weight", [256, 1024, 1, 1]], ["bn1.weight", [256]], ["bn1.bias", [256]], ["conv2.weight", [256, 256, 3, 3]], ["bn2.weight", [256]], ["bn2.bias", [256]], ["conv3.weight", [1024, 256, 1, 1]], ["bn3.weight", [1024]], ["bn3.bias", [1024]]], "output_shape": [[4, 1024, 16, 16]], "num_parameters": [262144, 256, 256, 589824, 256, 256, 262144, 1024, 1024]}, {"name": "layer3.3", "id": 139931210349248, "class_name": "Bottleneck(\n  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act1): ReLU(inplace=True)\n  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act2): ReLU(inplace=True)\n  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act3): ReLU(inplace=True)\n)", "parameters": [["conv1.weight", [256, 1024, 1, 1]], ["bn1.weight", [256]], ["bn1.bias", [256]], ["conv2.weight", [256, 256, 3, 3]], ["bn2.weight", [256]], ["bn2.bias", [256]], ["conv3.weight", [1024, 256, 1, 1]], ["bn3.weight", [1024]], ["bn3.bias", [1024]]], "output_shape": [[4, 1024, 16, 16]], "num_parameters": [262144, 256, 256, 589824, 256, 256, 262144, 1024, 1024]}, {"name": "layer3.4", "id": 139931210349776, "class_name": "Bottleneck(\n  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act1): ReLU(inplace=True)\n  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act2): ReLU(inplace=True)\n  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act3): ReLU(inplace=True)\n)", "parameters": [["conv1.weight", [256, 1024, 1, 1]], ["bn1.weight", [256]], ["bn1.bias", [256]], ["conv2.weight", [256, 256, 3, 3]], ["bn2.weight", [256]], ["bn2.bias", [256]], ["conv3.weight", [1024, 256, 1, 1]], ["bn3.weight", [1024]], ["bn3.bias", [1024]]], "output_shape": [[4, 1024, 16, 16]], "num_parameters": [262144, 256, 256, 589824, 256, 256, 262144, 1024, 1024]}, {"name": "layer3.5", "id": 139931209660400, "class_name": "Bottleneck(\n  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act1): ReLU(inplace=True)\n  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act2): ReLU(inplace=True)\n  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act3): ReLU(inplace=True)\n)", "parameters": [["conv1.weight", [256, 1024, 1, 1]], ["bn1.weight", [256]], ["bn1.bias", [256]], ["conv2.weight", [256, 256, 3, 3]], ["bn2.weight", [256]], ["bn2.bias", [256]], ["conv3.weight", [1024, 256, 1, 1]], ["bn3.weight", [1024]], ["bn3.bias", [1024]]], "output_shape": [[4, 1024, 16, 16]], "num_parameters": [262144, 256, 256, 589824, 256, 256, 262144, 1024, 1024]}, {"name": "layer4.0", "id": 139931209659632, "class_name": "Bottleneck(\n  (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act1): ReLU(inplace=True)\n  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act2): ReLU(inplace=True)\n  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act3): ReLU(inplace=True)\n  (downsample): Sequential(\n    (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n)", "parameters": [["conv1.weight", [512, 1024, 1, 1]], ["bn1.weight", [512]], ["bn1.bias", [512]], ["conv2.weight", [512, 512, 3, 3]], ["bn2.weight", [512]], ["bn2.bias", [512]], ["conv3.weight", [2048, 512, 1, 1]], ["bn3.weight", [2048]], ["bn3.bias", [2048]], ["downsample.0.weight", [2048, 1024, 1, 1]], ["downsample.1.weight", [2048]], ["downsample.1.bias", [2048]]], "output_shape": [[4, 2048, 8, 8]], "num_parameters": [524288, 512, 512, 2359296, 512, 512, 1048576, 2048, 2048, 2097152, 2048, 2048]}, {"name": "layer4.1", "id": 139931209659104, "class_name": "Bottleneck(\n  (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act1): ReLU(inplace=True)\n  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act2): ReLU(inplace=True)\n  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act3): ReLU(inplace=True)\n)", "parameters": [["conv1.weight", [512, 2048, 1, 1]], ["bn1.weight", [512]], ["bn1.bias", [512]], ["conv2.weight", [512, 512, 3, 3]], ["bn2.weight", [512]], ["bn2.bias", [512]], ["conv3.weight", [2048, 512, 1, 1]], ["bn3.weight", [2048]], ["bn3.bias", [2048]]], "output_shape": [[4, 2048, 8, 8]], "num_parameters": [1048576, 512, 512, 2359296, 512, 512, 1048576, 2048, 2048]}, {"name": "layer4.2", "id": 139931209660496, "class_name": "Bottleneck(\n  (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act1): ReLU(inplace=True)\n  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act2): ReLU(inplace=True)\n  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act3): ReLU(inplace=True)\n)", "parameters": [["conv1.weight", [512, 2048, 1, 1]], ["bn1.weight", [512]], ["bn1.bias", [512]], ["conv2.weight", [512, 512, 3, 3]], ["bn2.weight", [512]], ["bn2.bias", [512]], ["conv3.weight", [2048, 512, 1, 1]], ["bn3.weight", [2048]], ["bn3.bias", [2048]]], "output_shape": [[4, 2048, 8, 8]], "num_parameters": [1048576, 512, 512, 2359296, 512, 512, 1048576, 2048, 2048]}, {"name": "to_patch_embedding", "id": 139931209620544, "class_name": "Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)", "parameters": [["weight", [512, 2048, 1, 1]]], "output_shape": [[4, 512, 8, 8]], "num_parameters": [1048576]}, {"name": "transformers.8", "id": 139931209620064, "class_name": "Transformer(\n  (dropout): Dropout(p=0.05, inplace=False)\n  (transformer): TransformerModule(\n    (layers): ModuleList(\n      (0): ModuleList(\n        (0): Residual(\n          (fn): PreNorm(\n            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n            (fn): Attention(\n              (to_qkv): Linear(in_features=512, out_features=1536, bias=False)\n              (to_out): Sequential(\n                (0): Linear(in_features=512, out_features=512, bias=True)\n                (1): Dropout(p=0.05, inplace=False)\n              )\n            )\n          )\n        )\n        (1): Residual(\n          (fn): PreNorm(\n            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n            (fn): FeedForward(\n              (net): Sequential(\n                (0): Linear(in_features=512, out_features=1024, bias=True)\n                (1): GELU()\n                (2): Dropout(p=0.05, inplace=False)\n                (3): Linear(in_features=1024, out_features=512, bias=True)\n                (4): Dropout(p=0.05, inplace=False)\n              )\n            )\n          )\n        )\n      )\n      (1): ModuleList(\n        (0): Residual(\n          (fn): PreNorm(\n            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n            (fn): Attention(\n              (to_qkv): Linear(in_features=512, out_features=1536, bias=False)\n              (to_out): Sequential(\n                (0): Linear(in_features=512, out_features=512, bias=True)\n                (1): Dropout(p=0.05, inplace=False)\n              )\n            )\n          )\n        )\n        (1): Residual(\n          (fn): PreNorm(\n            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n            (fn): FeedForward(\n              (net): Sequential(\n                (0): Linear(in_features=512, out_features=1024, bias=True)\n                (1): GELU()\n                (2): Dropout(p=0.05, inplace=False)\n                (3): Linear(in_features=1024, out_features=512, bias=True)\n                (4): Dropout(p=0.05, inplace=False)\n              )\n            )\n          )\n        )\n      )\n    )\n  )\n  (to_latent): Identity()\n  (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n)", "parameters": [["token_0", [1, 1, 512]], ["transformer.layers.0.0.fn.norm.weight", [512]], ["transformer.layers.0.0.fn.norm.bias", [512]], ["transformer.layers.0.0.fn.fn.to_qkv.weight", [1536, 512]], ["transformer.layers.0.0.fn.fn.to_out.0.weight", [512, 512]], ["transformer.layers.0.0.fn.fn.to_out.0.bias", [512]], ["transformer.layers.0.1.fn.norm.weight", [512]], ["transformer.layers.0.1.fn.norm.bias", [512]], ["transformer.layers.0.1.fn.fn.net.0.weight", [1024, 512]], ["transformer.layers.0.1.fn.fn.net.0.bias", [1024]], ["transformer.layers.0.1.fn.fn.net.3.weight", [512, 1024]], ["transformer.layers.0.1.fn.fn.net.3.bias", [512]], ["transformer.layers.1.0.fn.norm.weight", [512]], ["transformer.layers.1.0.fn.norm.bias", [512]], ["transformer.layers.1.0.fn.fn.to_qkv.weight", [1536, 512]], ["transformer.layers.1.0.fn.fn.to_out.0.weight", [512, 512]], ["transformer.layers.1.0.fn.fn.to_out.0.bias", [512]], ["transformer.layers.1.1.fn.norm.weight", [512]], ["transformer.layers.1.1.fn.norm.bias", [512]], ["transformer.layers.1.1.fn.fn.net.0.weight", [1024, 512]], ["transformer.layers.1.1.fn.fn.net.0.bias", [1024]], ["transformer.layers.1.1.fn.fn.net.3.weight", [512, 1024]], ["transformer.layers.1.1.fn.fn.net.3.bias", [512]], ["layer_norm.weight", [512]], ["layer_norm.bias", [512]]], "output_shape": [[[[0], [0], [0], [0], [0], [0], 0, [0], 0, [0], 0, 0], [[0], [0], 0, [0], 0, 0]]], "num_parameters": [512, 512, 512, 786432, 262144, 512, 512, 512, 524288, 1024, 524288, 512, 512, 512, 786432, 262144, 512, 512, 512, 524288, 1024, 524288, 512, 512, 512]}, {"name": "transformers.4", "id": 139931209636832, "class_name": "Transformer(\n  (dropout): Dropout(p=0.05, inplace=False)\n  (transformer): TransformerModule(\n    (layers): ModuleList(\n      (0): ModuleList(\n        (0): Residual(\n          (fn): PreNorm(\n            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n            (fn): Attention(\n              (to_qkv): Linear(in_features=512, out_features=1536, bias=False)\n              (to_out): Sequential(\n                (0): Linear(in_features=512, out_features=512, bias=True)\n                (1): Dropout(p=0.05, inplace=False)\n              )\n            )\n          )\n        )\n        (1): Residual(\n          (fn): PreNorm(\n            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n            (fn): FeedForward(\n              (net): Sequential(\n                (0): Linear(in_features=512, out_features=1024, bias=True)\n                (1): GELU()\n                (2): Dropout(p=0.05, inplace=False)\n                (3): Linear(in_features=1024, out_features=512, bias=True)\n                (4): Dropout(p=0.05, inplace=False)\n              )\n            )\n          )\n        )\n      )\n      (1): ModuleList(\n        (0): Residual(\n          (fn): PreNorm(\n            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n            (fn): Attention(\n              (to_qkv): Linear(in_features=512, out_features=1536, bias=False)\n              (to_out): Sequential(\n                (0): Linear(in_features=512, out_features=512, bias=True)\n                (1): Dropout(p=0.05, inplace=False)\n              )\n            )\n          )\n        )\n        (1): Residual(\n          (fn): PreNorm(\n            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n            (fn): FeedForward(\n              (net): Sequential(\n                (0): Linear(in_features=512, out_features=1024, bias=True)\n                (1): GELU()\n                (2): Dropout(p=0.05, inplace=False)\n                (3): Linear(in_features=1024, out_features=512, bias=True)\n                (4): Dropout(p=0.05, inplace=False)\n              )\n            )\n          )\n        )\n      )\n    )\n  )\n  (to_latent): Identity()\n  (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n)", "parameters": [["token_0", [1, 1, 512]], ["transformer.layers.0.0.fn.norm.weight", [512]], ["transformer.layers.0.0.fn.norm.bias", [512]], ["transformer.layers.0.0.fn.fn.to_qkv.weight", [1536, 512]], ["transformer.layers.0.0.fn.fn.to_out.0.weight", [512, 512]], ["transformer.layers.0.0.fn.fn.to_out.0.bias", [512]], ["transformer.layers.0.1.fn.norm.weight", [512]], ["transformer.layers.0.1.fn.norm.bias", [512]], ["transformer.layers.0.1.fn.fn.net.0.weight", [1024, 512]], ["transformer.layers.0.1.fn.fn.net.0.bias", [1024]], ["transformer.layers.0.1.fn.fn.net.3.weight", [512, 1024]], ["transformer.layers.0.1.fn.fn.net.3.bias", [512]], ["transformer.layers.1.0.fn.norm.weight", [512]], ["transformer.layers.1.0.fn.norm.bias", [512]], ["transformer.layers.1.0.fn.fn.to_qkv.weight", [1536, 512]], ["transformer.layers.1.0.fn.fn.to_out.0.weight", [512, 512]], ["transformer.layers.1.0.fn.fn.to_out.0.bias", [512]], ["transformer.layers.1.1.fn.norm.weight", [512]], ["transformer.layers.1.1.fn.norm.bias", [512]], ["transformer.layers.1.1.fn.fn.net.0.weight", [1024, 512]], ["transformer.layers.1.1.fn.fn.net.0.bias", [1024]], ["transformer.layers.1.1.fn.fn.net.3.weight", [512, 1024]], ["transformer.layers.1.1.fn.fn.net.3.bias", [512]], ["layer_norm.weight", [512]], ["layer_norm.bias", [512]]], "output_shape": [[[[0], [0], [0], [0], [0], [0], 0, [0], 0, [0], 0, 0], [[0], [0], 0, [0], 0, 0]]], "num_parameters": [512, 512, 512, 786432, 262144, 512, 512, 512, 524288, 1024, 524288, 512, 512, 512, 786432, 262144, 512, 512, 512, 524288, 1024, 524288, 512, 512, 512]}, {"name": "transformers.2", "id": 139931209637744, "class_name": "Transformer(\n  (dropout): Dropout(p=0.05, inplace=False)\n  (transformer): TransformerModule(\n    (layers): ModuleList(\n      (0): ModuleList(\n        (0): Residual(\n          (fn): PreNorm(\n            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n            (fn): Attention(\n              (to_qkv): Linear(in_features=512, out_features=1536, bias=False)\n              (to_out): Sequential(\n                (0): Linear(in_features=512, out_features=512, bias=True)\n                (1): Dropout(p=0.05, inplace=False)\n              )\n            )\n          )\n        )\n        (1): Residual(\n          (fn): PreNorm(\n            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n            (fn): FeedForward(\n              (net): Sequential(\n                (0): Linear(in_features=512, out_features=1024, bias=True)\n                (1): GELU()\n                (2): Dropout(p=0.05, inplace=False)\n                (3): Linear(in_features=1024, out_features=512, bias=True)\n                (4): Dropout(p=0.05, inplace=False)\n              )\n            )\n          )\n        )\n      )\n      (1): ModuleList(\n        (0): Residual(\n          (fn): PreNorm(\n            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n            (fn): Attention(\n              (to_qkv): Linear(in_features=512, out_features=1536, bias=False)\n              (to_out): Sequential(\n                (0): Linear(in_features=512, out_features=512, bias=True)\n                (1): Dropout(p=0.05, inplace=False)\n              )\n            )\n          )\n        )\n        (1): Residual(\n          (fn): PreNorm(\n            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n            (fn): FeedForward(\n              (net): Sequential(\n                (0): Linear(in_features=512, out_features=1024, bias=True)\n                (1): GELU()\n                (2): Dropout(p=0.05, inplace=False)\n                (3): Linear(in_features=1024, out_features=512, bias=True)\n                (4): Dropout(p=0.05, inplace=False)\n              )\n            )\n          )\n        )\n      )\n    )\n  )\n  (to_latent): Identity()\n  (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n)", "parameters": [["token_0", [1, 1, 512]], ["transformer.layers.0.0.fn.norm.weight", [512]], ["transformer.layers.0.0.fn.norm.bias", [512]], ["transformer.layers.0.0.fn.fn.to_qkv.weight", [1536, 512]], ["transformer.layers.0.0.fn.fn.to_out.0.weight", [512, 512]], ["transformer.layers.0.0.fn.fn.to_out.0.bias", [512]], ["transformer.layers.0.1.fn.norm.weight", [512]], ["transformer.layers.0.1.fn.norm.bias", [512]], ["transformer.layers.0.1.fn.fn.net.0.weight", [1024, 512]], ["transformer.layers.0.1.fn.fn.net.0.bias", [1024]], ["transformer.layers.0.1.fn.fn.net.3.weight", [512, 1024]], ["transformer.layers.0.1.fn.fn.net.3.bias", [512]], ["transformer.layers.1.0.fn.norm.weight", [512]], ["transformer.layers.1.0.fn.norm.bias", [512]], ["transformer.layers.1.0.fn.fn.to_qkv.weight", [1536, 512]], ["transformer.layers.1.0.fn.fn.to_out.0.weight", [512, 512]], ["transformer.layers.1.0.fn.fn.to_out.0.bias", [512]], ["transformer.layers.1.1.fn.norm.weight", [512]], ["transformer.layers.1.1.fn.norm.bias", [512]], ["transformer.layers.1.1.fn.fn.net.0.weight", [1024, 512]], ["transformer.layers.1.1.fn.fn.net.0.bias", [1024]], ["transformer.layers.1.1.fn.fn.net.3.weight", [512, 1024]], ["transformer.layers.1.1.fn.fn.net.3.bias", [512]], ["layer_norm.weight", [512]], ["layer_norm.bias", [512]]], "output_shape": [[[[0], [0], [0], [0], [0], [0], 0, [0], 0, [0], 0, 0], [[0], [0], 0, [0], 0, 0]]], "num_parameters": [512, 512, 512, 786432, 262144, 512, 512, 512, 524288, 1024, 524288, 512, 512, 512, 786432, 262144, 512, 512, 512, 524288, 1024, 524288, 512, 512, 512]}, {"name": "fc", "id": 139931099662848, "class_name": "Linear(in_features=512, out_features=1000, bias=True)", "parameters": [["weight", [1000, 512]], ["bias", [1000]]], "output_shape": [[4, 1000]], "num_parameters": [512000, 1000]}], "edges": []}